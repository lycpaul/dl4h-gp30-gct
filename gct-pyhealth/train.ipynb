{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:38.906209Z",
     "end_time": "2023-05-01T01:51:40.251156Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "from gctpyhealth.process_eicu_dataset import get_eicu_datasets\n",
    "from gctpyhealth.utils import *\n",
    "from gctpyhealth.gct import GCT\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchsummary as summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:40.253377Z",
     "end_time": "2023-05-01T01:51:40.255510Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    pass\n",
    "\n",
    "\n",
    "args = Args()\n",
    "args.learning_rate = 0.00022\n",
    "args.max_steps = 100  ### for short run # 1000000\n",
    "args.do_train = True\n",
    "args.do_eval = True\n",
    "args.do_test = True\n",
    "args.warmup = 0.05  # default\n",
    "args.intermediate_size = 256  # default\n",
    "args.eps = 1e-8  # default\n",
    "args.max_grad_norm = 1.0  # default\n",
    "args.eval_batch_size = 32\n",
    "args.logging_steps = 100  # default\n",
    "args.num_train_epochs = 5  # default\n",
    "args.seed = 42  # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:40.256616Z",
     "end_time": "2023-05-01T01:51:40.261461Z"
    }
   },
   "outputs": [],
   "source": [
    "label_key = \"expired\"\n",
    "fold = 0\n",
    "data_dir = \"eicu_data\"\n",
    "eicu_csv_dir = \"../eicu_csv\"\n",
    "output_dir = \"eicu_output/model_pyhealth\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:40.262466Z",
     "end_time": "2023-05-01T01:51:40.266693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the log data\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "logging_dir = os.path.join(output_dir, 'logging')\n",
    "if not os.path.exists(logging_dir):\n",
    "    os.makedirs(logging_dir)\n",
    "tb_writer = SummaryWriter(log_dir=logging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading eICU dataset\n",
      "\n",
      "Statistics of base dataset (dev=True):\n",
      "\t- Dataset: eICUDataset\n",
      "\t- Number of patients: 3671\n",
      "\t- Number of visits: 5000\n",
      "\t- Number of visits per patient: 1.3620\n",
      "\t- Number of events per visit in admissionDx: 2.7186\n",
      "\t- Number of events per visit in diagnosisString: 4.8976\n",
      "\t- Number of events per visit in treatment: 0.0000\n",
      "\n",
      "\n",
      "dataset.patients: patient_id -> <Patient>\n",
      "\n",
      "<Patient>\n",
      "    - visits: visit_id -> <Visit> \n",
      "    - other patient-level info\n",
      "    \n",
      "    <Visit>\n",
      "        - event_list_dict: table_name -> List[Event]\n",
      "        - other visit-level info\n",
      "    \n",
      "        <Event>\n",
      "            - code: str\n",
      "            - other event-level info\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading the eICU dataset\n",
    "from pyhealth.datasets import eICUDataset\n",
    "\n",
    "print('Loading eICU dataset')\n",
    "eicu_ds = eICUDataset(\n",
    "    root=eicu_csv_dir,\n",
    "    tables=[\"admissionDx\", \"diagnosisString\", \"treatment\"],\n",
    "    refresh_cache=False,\n",
    "    dev=True\n",
    ")\n",
    "\n",
    "eicu_ds.stat()\n",
    "eicu_ds.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:40.268413Z",
     "end_time": "2023-05-01T01:51:40.641863Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:40.626639Z",
     "end_time": "2023-05-01T01:51:42.937779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached data, loading...\n",
      "loading cached data takes: 2.3421475887298584s\n"
     ]
    }
   ],
   "source": [
    "# fetch the datatset from caches\n",
    "datasets, prior_guides = get_eicu_datasets(data_dir, eicu_csv_dir, fold=fold)\n",
    "train_dataset, eval_dataset, test_dataset = datasets\n",
    "train_priors, eval_priors, test_priors = prior_guides\n",
    "train_priors_dataset = eICUPriorDataset(train_priors)\n",
    "eval_priors_dataset = eICUPriorDataset(eval_priors)\n",
    "test_priors_dataset = eICUPriorDataset(test_priors)\n",
    "\n",
    "# prepare data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "train_priors_dataloader = DataLoader(train_priors_dataset,\n",
    "                                     batch_size=batch_size, collate_fn=priors_collate_fn)\n",
    "eval_priors_dataloader = DataLoader(eval_priors_dataset,\n",
    "                                    batch_size=batch_size, collate_fn=priors_collate_fn)\n",
    "test_priors_dataloader = DataLoader(test_priors_dataset,\n",
    "                                    batch_size=batch_size, collate_fn=priors_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/01/2023 01:51:42 - INFO - __main__ - ***** Using CUDA device *****\n"
     ]
    }
   ],
   "source": [
    "# check if cuda is available\n",
    "n_gpu = torch.cuda.device_count()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_device(device)\n",
    "    logger.info('***** Using CUDA device *****')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:42.934300Z",
     "end_time": "2023-05-01T01:51:42.944589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from pyhealth.models import Transformer\n",
    "from gctpyhealth.gct import GCT\n",
    "\n",
    "model = GCT(\n",
    "    dataset=eicu_ds,\n",
    "    feature_keys=['conditions_hash',\n",
    "                  'procedures_hash'],\n",
    "    label_key=\"expired\",\n",
    "    mode=\"binary\",\n",
    ")\n",
    "model = model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:42.941369Z",
     "end_time": "2023-05-01T01:51:43.722347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/01/2023 01:51:43 - INFO - __main__ - ***** Running Training *****\n",
      "05/01/2023 01:51:43 - INFO - __main__ -  Num examples = 32820\n",
      "05/01/2023 01:51:43 - INFO - __main__ -  Num epochs = 1\n",
      "05/01/2023 01:51:43 - INFO - __main__ -  Train batch size = 32\n",
      "05/01/2023 01:51:43 - INFO - __main__ -  Total optimization steps = 100\n"
     ]
    }
   ],
   "source": [
    "# prepare optimizer, scheduler\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "if args.max_steps > 0:\n",
    "    max_steps = args.max_steps\n",
    "    num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
    "        args.max_steps % num_update_steps_per_epoch > 0)\n",
    "else:\n",
    "    max_steps = int(num_update_steps_per_epoch * args.num_train_epochs)\n",
    "    num_train_epochs = args.num_train_epochs\n",
    "num_train_epochs = int(np.ceil(num_train_epochs))\n",
    "\n",
    "args.eval_steps = num_update_steps_per_epoch // 2\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=args.learning_rate)\n",
    "warmup_steps = max_steps // (1 / args.warmup)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, num_training_steps=max_steps)\n",
    "\n",
    "logger.info('***** Running Training *****')\n",
    "logger.info(' Num examples = {}'.format(len(train_dataloader.dataset)))\n",
    "logger.info(' Num epochs = {}'.format(num_train_epochs))\n",
    "logger.info(' Train batch size = {}'.format(batch_size))\n",
    "logger.info(' Total optimization steps = {}'.format(max_steps))\n",
    "\n",
    "epochs_trained = 0\n",
    "global_step = 0\n",
    "tr_loss = torch.tensor(0.0).to(device)\n",
    "logging_loss_scalar = 0.0\n",
    "model.zero_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:43.725961Z",
     "end_time": "2023-05-01T01:51:43.731373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1026 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   0%|          | 1/1026 [00:00<10:22,  1.65it/s]\u001B[A\n",
      "Iteration:   1%|          | 12/1026 [00:00<00:45, 22.13it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 23/1026 [00:00<00:24, 40.71it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 35/1026 [00:00<00:17, 58.07it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 47/1026 [00:01<00:13, 72.41it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 59/1026 [00:01<00:11, 83.19it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 70/1026 [00:01<00:10, 88.16it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 82/1026 [00:01<00:09, 95.60it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 100/1026 [00:01<00:14, 66.10it/s]\u001B[A\n",
      "Epoch: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "05/01/2023 01:51:45 - INFO - root - \n",
      "\n",
      "Training completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.514261932373047, 'learning_rate': 0.0, 'step': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_pbar = trange(epochs_trained, num_train_epochs, desc='Epoch')\n",
    "for epoch in range(epochs_trained, num_train_epochs):\n",
    "    epoch_pbar = tqdm(train_dataloader, desc='Iteration')\n",
    "    for data, priors_data in zip(train_dataloader, train_priors_dataloader):\n",
    "        model.train()\n",
    "        data, priors_data = prepare_data(data, priors_data, device)\n",
    "\n",
    "        # [loss, logits, all_hidden_states, all_attentions]\n",
    "        outputs = model(data, priors_data)\n",
    "        loss = outputs['loss']\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean()\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.detach()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "        global_step += 1\n",
    "\n",
    "        if (args.logging_steps > 0 and global_step % args.logging_steps == 0):\n",
    "            logs = {}\n",
    "            tr_loss_scalar = tr_loss.item()\n",
    "            logs['loss'] = (tr_loss_scalar - logging_loss_scalar) / args.logging_steps\n",
    "            logs['learning_rate'] = scheduler.get_last_lr()[0]\n",
    "            logging_loss_scalar = tr_loss_scalar\n",
    "            if tb_writer:\n",
    "                for k, v in logs.items():\n",
    "                    if isinstance(v, (int, float)):\n",
    "                        tb_writer.add_scalar(k, v, global_step)\n",
    "                tb_writer.flush()\n",
    "            output = {**logs, **{\"step\": global_step}}\n",
    "            print(output)\n",
    "\n",
    "        if (args.eval_steps > 0 and global_step % args.eval_steps == 0):\n",
    "            metrics = prediction_loop(device, label_key, model, eval_dataloader, eval_priors_dataloader)\n",
    "            logger.info('**** Checkpoint Eval Results ****')\n",
    "            for key, value in metrics.items():\n",
    "                logger.info('{} = {}'.format(key, value))\n",
    "                tb_writer.add_scalar(key, value, global_step)\n",
    "\n",
    "        epoch_pbar.update(1)\n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "    epoch_pbar.close()\n",
    "    train_pbar.update(1)\n",
    "    if global_step >= max_steps:\n",
    "        break\n",
    "\n",
    "train_pbar.close()\n",
    "if tb_writer:\n",
    "    tb_writer.close()\n",
    "\n",
    "logging.info('\\n\\nTraining completed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:43.735690Z",
     "end_time": "2023-05-01T01:51:45.259831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/01/2023 01:51:45 - INFO - __main__ - *** Evaluate ***\n",
      "05/01/2023 01:51:45 - INFO - __main__ -  Num examples = 4103\n",
      "Evaluating: 129it [00:00, 312.18it/s]\n",
      "/home/lycpaul/anaconda3/envs/dl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "05/01/2023 01:51:45 - INFO - __main__ - *** Eval Results ***\n",
      "05/01/2023 01:51:45 - INFO - __main__ - eval_loss = 2.7047904289672355\n",
      "05/01/2023 01:51:45 - INFO - __main__ - eval_AUCPR = 0.5369242018035584\n",
      "05/01/2023 01:51:45 - INFO - __main__ - eval_AUROC = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "eval_results = {}\n",
    "logger.info('*** Evaluate ***')\n",
    "logger.info(' Num examples = {}'.format(len(eval_dataloader.dataset)))\n",
    "eval_result = prediction_loop(device, label_key, model, eval_dataloader, eval_priors_dataloader)\n",
    "output_eval_file = os.path.join(output_dir, 'eval_results.txt')\n",
    "with open(output_eval_file, 'w') as writer:\n",
    "    logger.info('*** Eval Results ***')\n",
    "    for key, value in eval_result.items():\n",
    "        logger.info(\"{} = {}\".format(key, value))\n",
    "        writer.write('{} = {}'.format(key, value))\n",
    "eval_results.update(eval_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:45.260504Z",
     "end_time": "2023-05-01T01:51:45.710893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/01/2023 01:51:45 - INFO - root - *** Test ***\n",
      "Testing: 129it [00:00, 327.46it/s]\n",
      "/home/lycpaul/anaconda3/envs/dl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "05/01/2023 01:51:46 - INFO - __main__ - **** Test results ****\n",
      "05/01/2023 01:51:46 - INFO - __main__ - eval_loss = 2.6953954154504323\n",
      "05/01/2023 01:51:46 - INFO - __main__ - eval_AUCPR = 0.5359493053863027\n",
      "05/01/2023 01:51:46 - INFO - __main__ - eval_AUROC = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Test and predict\n",
    "logging.info('*** Test ***')\n",
    "test_result = prediction_loop(device, label_key, model, test_dataloader, test_priors_dataloader, description='Testing')\n",
    "output_test_file = os.path.join(output_dir, 'test_results.txt')\n",
    "with open(output_test_file, 'w') as writer:\n",
    "    logger.info('**** Test results ****')\n",
    "    for key, value in test_result.items():\n",
    "        logger.info('{} = {}'.format(key, value))\n",
    "        writer.write('{} = {}'.format(key, value))\n",
    "eval_results.update(test_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T01:51:45.710345Z",
     "end_time": "2023-05-01T01:51:46.126534Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
