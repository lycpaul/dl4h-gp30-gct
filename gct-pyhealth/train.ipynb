{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Graph Convolution Transformer (GCT) for eICU dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 0: Import libaries, prepare proper parameters**\n",
    "- **[README]:** We provide a set of default parameters for users to run the experiments. Users can also change the parameters to fit their own needs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from gctpyhealth.process_eicu_dataset import get_eicu_datasets\n",
    "from gctpyhealth.utils import *\n",
    "from gctpyhealth.gct import GCT\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchsummary as summary\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:28.829087Z",
     "end_time": "2023-05-01T23:38:28.875345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:28.833122Z",
     "end_time": "2023-05-01T23:38:28.894739Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, prediction_task: str):\n",
    "        if prediction_task == \"expired\":\n",
    "            self.label_key = \"expired\"\n",
    "            self.learning_rate = 0.00011\n",
    "            self.reg_coef = 1.5\n",
    "            self.hidden_dropout = 0.72\n",
    "        elif prediction_task == \"readmission\":\n",
    "            self.label_key = \"readmission\"\n",
    "            self.learning_rate = 0.00022\n",
    "            self.reg_coef = 0.1\n",
    "            self.hidden_dropout = 0.08\n",
    "        else:\n",
    "            raise ValueError(\"Invalid prediction task: {}\".format(prediction_task))\n",
    "\n",
    "        # Training arguments\n",
    "        self.max_steps = 5000  ### for short run # 1000000\n",
    "        self.warmup = 0.05  # default\n",
    "        self.logging_steps = 100  # default\n",
    "        self.num_train_epochs = 1  # default\n",
    "        self.seed = 42  # default\n",
    "\n",
    "        # Model parameters arguments\n",
    "        self.embedding_dim = 128\n",
    "        self.max_num_codes = 50\n",
    "        self.num_stacks = 2\n",
    "        self.batch_size = 32\n",
    "        self.prior_scalar = 0.5\n",
    "        self.num_heads = 1\n",
    "\n",
    "        # save and load the cache/dataset/env path (required)\n",
    "        self.fold = 0\n",
    "        self.data_dir = \"eicu_data\"\n",
    "        self.eicu_csv_dir = \"../eicu_csv\"\n",
    "        # timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        # self.output_dir = \"eicu_output/model_pyhealth_\" + timestamp\n",
    "        self.output_dir = \"eicu_output/model_pyhealth_\" + self.label_key\n",
    "\n",
    "        # save and load the models (optional)\n",
    "        self.save_model = True\n",
    "        self.load_prev_model = True\n",
    "        self.prev_model_path = \"eicu_output/model_pyhealth_\" + self.label_key + \"/model.pt\"\n",
    "\n",
    "\n",
    "args = Args(\"expired\")\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 1: Load dataset**\n",
    "- **[README]:** We call [pyhealth.datasets](https://pyhealth.readthedocs.io/en/latest/api/datasets.html) to process and obtain the dataset.\n",
    "  - `root` is the arguments directing to the data folder.\n",
    "  - `tables` is a list of table names from raw databases, which specifies the information that will be used in building the pipeline. Currently, we provide [MIMIC3Dataset](https://pyhealth.readthedocs.io/en/latest/api/datasets/pyhealth.datasets.MIMIC3Dataset.html), [MIMIC4Dataset](https://pyhealth.readthedocs.io/en/latest/api/datasets/pyhealth.datasets.MIMIC4Dataset.html), [eICUDataset](https://pyhealth.readthedocs.io/en/latest/api/datasets/pyhealth.datasets.eICUDataset.html), [OMOPDataset](https://pyhealth.readthedocs.io/en/latest/api/datasets/pyhealth.datasets.OMOPDataset.html).\n",
    "  - `code_mapping [default: None]` asks a directionary input, specifying the new coding systems for each data table. For example, `{\"NDC\": (\"ATC\", {\"target_kwargs\": {\"level\": 3}})}` means that our pyhealth will automatically change the codings from `NDC` into ATC-3 level for tables if any.\n",
    "  - `dev`: if set `True`, will only load a smaller set of patients.\n",
    "- **[Next Step]:** This `pyhealth.datasets` object will be used in **Step 2**.\n",
    "- **[Advanced Use Case]:** Researchers can use the dict-based output alone `dataset.patients` alone for supporting their own tasks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:28.843786Z",
     "end_time": "2023-05-01T23:38:28.933084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the log data\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "logging_dir = os.path.join(args.output_dir, 'logging')\n",
    "if not os.path.exists(logging_dir):\n",
    "    os.makedirs(logging_dir)\n",
    "tb_writer = SummaryWriter(log_dir=logging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loading the eICU dataset\n",
    "from pyhealth.datasets import eICUDataset\n",
    "\n",
    "print('Loading eICU dataset')\n",
    "eicu_ds = eICUDataset(\n",
    "    root=args.eicu_csv_dir,\n",
    "    tables=[\"admissionDx\", \"diagnosisString\", \"treatment\"],\n",
    "    refresh_cache=False,\n",
    "    dev=True\n",
    ")\n",
    "\n",
    "print(eicu_ds.stat())\n",
    "print(eicu_ds.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:28.890275Z",
     "end_time": "2023-05-01T23:38:29.303057Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 2: Create Dataloader**\n",
    "- **[README]:** We can also load the preprocessed datasets dict from cache and create the dataloader accordingly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:29.300988Z",
     "end_time": "2023-05-01T23:38:31.714903Z"
    }
   },
   "outputs": [],
   "source": [
    "# fetch the datatset from caches\n",
    "datasets, prior_guides = get_eicu_datasets(args.data_dir, args.eicu_csv_dir, fold=args.fold)\n",
    "train_dataset, eval_dataset, test_dataset = datasets\n",
    "train_priors, eval_priors, test_priors = prior_guides\n",
    "train_priors_dataset = eICUPriorDataset(train_priors)\n",
    "eval_priors_dataset = eICUPriorDataset(eval_priors)\n",
    "test_priors_dataset = eICUPriorDataset(test_priors)\n",
    "\n",
    "# prepare data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=args.batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "\n",
    "train_priors_dataloader = DataLoader(train_priors_dataset,\n",
    "                                     batch_size=args.batch_size, collate_fn=priors_collate_fn)\n",
    "eval_priors_dataloader = DataLoader(eval_priors_dataset,\n",
    "                                    batch_size=args.batch_size, collate_fn=priors_collate_fn)\n",
    "test_priors_dataloader = DataLoader(test_priors_dataset,\n",
    "                                    batch_size=args.batch_size, collate_fn=priors_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if gpu/cuda is available\n",
    "n_gpu = torch.cuda.device_count()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_device(device)\n",
    "    logger.info('***** Using CUDA device *****')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:31.710648Z",
     "end_time": "2023-05-01T23:38:31.715119Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 3: Define ML Model**\n",
    "- **[README]:** We initialize an ML model for the healthcare task by calling [pyhealth.models](https://pyhealth.readthedocs.io/en/latest/api/models.html).\n",
    "- **[Next Step]:** This `pyhealth.models` object will be used in **Step 4**.\n",
    "- **[Other Use Case]:** Our `pyhealth.models` object is as general as any instance from `torch.nn.Module`. Users may use it separately for supporting any other customized pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from pyhealth.models import Transformer\n",
    "from gctpyhealth.gct import GCT\n",
    "\n",
    "model = GCT(\n",
    "    dataset=eicu_ds,\n",
    "    feature_keys=['conditions_hash',\n",
    "                  'procedures_hash'],\n",
    "    label_key=args.label_key,\n",
    "    mode=\"binary\",\n",
    ")\n",
    "\n",
    "# loading previous checkpoint if available\n",
    "checkpoint = None\n",
    "if args.load_prev_model:\n",
    "    checkpoint = torch.load(args.prev_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model = model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:31.710686Z",
     "end_time": "2023-05-01T23:38:31.775418Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 4: Model Training**\n",
    "- **[README]:** We call our [pyhealth.train.Trainer](https://pyhealth.readthedocs.io/en/latest/api/trainer.html) to train the model by giving the `train_loader`, the `val_loader`, val_metric, and specify other arguemnts, such as epochs, optimizer, learning rate, etc. The trainer will automatically save the best model and output the path in the end.\n",
    "- **[Next Step]:** The best model will be used in **Step 5** for evaluation.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute how steps and epoch is required\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "if args.max_steps > 0:\n",
    "    max_steps = args.max_steps\n",
    "    num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
    "        args.max_steps % num_update_steps_per_epoch > 0)\n",
    "else:\n",
    "    max_steps = int(num_update_steps_per_epoch * args.num_train_epochs)\n",
    "    num_train_epochs = args.num_train_epochs\n",
    "num_train_epochs = int(np.ceil(num_train_epochs))\n",
    "\n",
    "args.eval_steps = num_update_steps_per_epoch // 2\n",
    "\n",
    "# prepare optimizer, scheduler\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=args.learning_rate)\n",
    "warmup_steps = max_steps // (1 / args.warmup)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, num_training_steps=max_steps)\n",
    "\n",
    "logger.info('***** Running Training *****')\n",
    "logger.info(' Num examples = {}'.format(len(train_dataloader.dataset)))\n",
    "logger.info(' Num epochs = {}'.format(num_train_epochs))\n",
    "logger.info(' Train batch size = {}'.format(args.batch_size))\n",
    "logger.info(' Total optimization steps = {}'.format(max_steps))\n",
    "\n",
    "epochs_trained = 0\n",
    "global_step = 0\n",
    "tr_loss = torch.tensor(0.0).to(device)\n",
    "logging_loss_scalar = 0.0\n",
    "model.zero_grad()\n",
    "\n",
    "# check if we have previous checkpoint\n",
    "if args.load_prev_model and checkpoint is not None:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    epochs_trained = checkpoint['epochs_trained']\n",
    "    global_step = checkpoint['global_step']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:31.740246Z",
     "end_time": "2023-05-01T23:38:31.788715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_outputs = None\n",
    "train_pbar = trange(epochs_trained, num_train_epochs, desc='Epoch')\n",
    "for epoch in range(epochs_trained, num_train_epochs):\n",
    "    epoch_pbar = tqdm(train_dataloader, desc='Iteration')\n",
    "    for data, priors_data in zip(train_dataloader, train_priors_dataloader):\n",
    "        model.train()\n",
    "        data, priors_data = prepare_data(data, priors_data, device)\n",
    "\n",
    "        # [loss, logits, all_hidden_states, all_attentions]\n",
    "        training_outputs = model(data, priors_data)\n",
    "        loss = training_outputs['loss']\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean()\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.detach()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        # update the global step\n",
    "        global_step += 1\n",
    "\n",
    "        # print out the training results\n",
    "        if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "            logs = {}\n",
    "            tr_loss_scalar = tr_loss.item()\n",
    "            logs['loss'] = (tr_loss_scalar - logging_loss_scalar) / args.logging_steps\n",
    "            logs['learning_rate'] = scheduler.get_last_lr()[0]\n",
    "            logging_loss_scalar = tr_loss_scalar\n",
    "            if tb_writer:\n",
    "                for k, v in logs.items():\n",
    "                    if isinstance(v, (int, float)):\n",
    "                        tb_writer.add_scalar(k, v, global_step)\n",
    "                tb_writer.flush()\n",
    "            output = {**logs, **{\"step\": global_step}}\n",
    "            print(output)\n",
    "\n",
    "        # print out the evaluation results\n",
    "        if args.eval_steps > 0 and global_step % args.eval_steps == 0:\n",
    "            metrics = prediction_loop(device, args.label_key,\n",
    "                                      model, eval_dataloader, eval_priors_dataloader)\n",
    "            logger.info('**** Checkpoint Eval Results ****')\n",
    "            for key, value in metrics.items():\n",
    "                logger.info('{} = {}'.format(key, value))\n",
    "                tb_writer.add_scalar(key, value, global_step)\n",
    "\n",
    "        epoch_pbar.update(1)\n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "\n",
    "    epoch_pbar.close()\n",
    "    train_pbar.update(1)\n",
    "    if global_step >= max_steps:\n",
    "        break\n",
    "\n",
    "train_pbar.close()\n",
    "if tb_writer:\n",
    "    tb_writer.close()\n",
    "\n",
    "logging.info('\\n\\nTraining completed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:31.754339Z",
     "end_time": "2023-05-01T23:38:59.013212Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 5: Evaluation**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "eval_results = {}\n",
    "\n",
    "logger.info('*** Evaluate ***')\n",
    "logger.info(' Num examples = {}'.format(len(eval_dataloader.dataset)))\n",
    "eval_result = prediction_loop(device, args.label_key, model, eval_dataloader, eval_priors_dataloader)\n",
    "output_eval_file = os.path.join(args.output_dir, 'eval_results.txt')\n",
    "\n",
    "with open(output_eval_file, 'a') as writer:\n",
    "    logger.info('*** Eval results @ steps:{} ***\\n'.format(global_step))\n",
    "    writer.write('*** Eval results @ steps:{} ***\\n'.format(global_step))\n",
    "    for key, value in eval_result.items():\n",
    "        logger.info('{} = {}\\n'.format(key, value))\n",
    "        writer.write('{} = {}\\n'.format(key, value))\n",
    "eval_results.update(eval_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:59.015045Z",
     "end_time": "2023-05-01T23:38:59.454694Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 6: Inference**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test and predict\n",
    "logging.info('*** Test ***')\n",
    "test_result = prediction_loop(device, args.label_key, model, test_dataloader, test_priors_dataloader,\n",
    "                              description='Testing')\n",
    "output_test_file = os.path.join(args.output_dir, 'test_results.txt')\n",
    "with open(output_test_file, 'a') as writer:\n",
    "    logger.info('*** Test results @ steps:{} ***\\n'.format(global_step))\n",
    "    writer.write('*** Test results @ steps:{} ***\\n'.format(global_step))\n",
    "    for key, value in test_result.items():\n",
    "        logger.info('{} = {}\\n'.format(key, value))\n",
    "        writer.write('{} = {}\\n'.format(key, value))\n",
    "eval_results.update(test_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:59.454382Z",
     "end_time": "2023-05-01T23:38:59.834822Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 7: Save model**\n",
    "Reference: [Saving and Loading Models](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print model's state_dict\n",
    "logger.info('Model state_dict:')\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:59.834370Z",
     "end_time": "2023-05-01T23:38:59.835096Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if enable save model option, save the model\n",
    "if args.save_model:\n",
    "    torch.save({\n",
    "        'epochs_trained': epochs_trained,\n",
    "        'global_step': global_step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss': training_outputs['loss'],\n",
    "        'all_hidden_states': training_outputs['all_hidden_states'],\n",
    "        'all_attentions': training_outputs['all_attentions']\n",
    "    }, args.output_dir + '/model.pt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T23:38:59.834412Z",
     "end_time": "2023-05-01T23:38:59.878322Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
